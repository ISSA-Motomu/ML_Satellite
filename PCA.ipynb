{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74de08e9",
   "metadata": {},
   "source": [
    "## 1. 主成分分析\n",
    "> 与えられた特徴量から新たな特徴量`主成分`を作り出し、元の特徴量よりも少ない数の変数（次元）でデータを説明する手法<br>\n",
    "\n",
    "![alt text](image.png)\n",
    "\n",
    "- 中心化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1151502",
   "metadata": {},
   "source": [
    "- 共分散行列　Covariance Matrix\n",
    "> 多次元であっても、共分散（二つの変数の関係）と分散を行列に並べているだけ\n",
    "$$\n",
    "\\Sigma = \n",
    "\\begin{pmatrix}\n",
    "\\text{Var}(x) & \\text{Cov}(x, y) & \\text{Cov}(x, z) \\\\\n",
    "\\text{Cov}(y, x) & \\text{Var}(y) & \\text{Cov}(y, z) \\\\\n",
    "\\text{Cov}(z, x) & \\text{Cov}(z, y) & \\text{Var}(z)\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54f2f94",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fbaa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class PCATensorFlow:\n",
    "    def __init__(self, n_components):\n",
    "        self.n_components = n_components\n",
    "        self.components_ = None\n",
    "        self.mean_ = None\n",
    "        self.eigenvalues_ = None\n",
    "\n",
    "    def fit(self, X):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X (tf.Tensor): Input data. Shape [n_samples, n_features]\n",
    "\n",
    "        中心化\n",
    "           まず各特徴量の平均を計算し、データから引く\n",
    "        \"\"\"\n",
    "        # tf.cast で型を float32 に統一（GPU演算の基本）\n",
    "        X = tf.cast(X, tf.float32)\n",
    "        \n",
    "        # 1. 中心化\n",
    "        self.mean_ = tf.reduce_mean(X, axis=0)\n",
    "        X_centered = X - self.mean_\n",
    "        \n",
    "        n_samples = tf.cast(tf.shape(X)[0], tf.float32)\n",
    "\n",
    "        # 2. 共分散行列の計算\n",
    "        # NumPyの dot ではなく、TensorFlowの行列積関数を使います。\n",
    "        # ヒント: [n_features, n_samples] x [n_samples, n_features] の形にする必要があります。\n",
    "        # transpose_a=True (Xを転置) または transpose_b=True (後ろを転置) の引数を活用します。\n",
    "        cov_matrix = [Q1] / (n_samples - 1)\n",
    "\n",
    "        # 3. 固有値分解 (Self-Adjoint Eigendecomposition)\n",
    "        # 対称行列専用の高速ソルバー tf.linalg.eigh を使います。\n",
    "        # これも昇順（小さい順）で返ってきます。\n",
    "        eigenvalues, eigenvectors = tf.linalg.eigh(cov_matrix)\n",
    "\n",
    "        # 4. ソート（降順）\n",
    "        # TensorFlowにはスライシングの他に、逆順にする専用関数があります（スライスでも可）。\n",
    "        # ここではインデックス順序を反転させる処理を記述してください。\n",
    "        # 例: Pythonのスライス記法 [::-1] はTensorでも有効です。\n",
    "        sorted_indices = tf.argsort(eigenvalues, direction='DESCENDING') \n",
    "        # ↑ TFでは便利な引数がありますが、もしスライスで書くなら？\n",
    "        # 今回はシンプルに [Q2] (変数名とスライス) を答えてください。\n",
    "        # ※ tf.argsortを使わず、すでに取得した eigenvalues, eigenvectors をどう逆順にするか\n",
    "        \n",
    "        # 修正: わかりやすくするために、tf.argsortを使わずに\n",
    "        # 「得られた結果を逆順にするスライス操作」を答えてください。\n",
    "        self.eigenvalues_ = eigenvalues[[Q2]]\n",
    "        self.eigenvectors_ = eigenvectors[:, [Q2]]\n",
    "\n",
    "        # 上位n成分を取得\n",
    "        self.components_ = self.eigenvectors_[:, :self.n_components]\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = tf.cast(X, tf.float32)\n",
    "        X_centered = X - self.mean_\n",
    "        \n",
    "        # 5. 射影\n",
    "        # TensorFlowの行列積で行ってください。\n",
    "        return [Q3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99917d0",
   "metadata": {},
   "source": [
    "### 2. 主成分分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf94cf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
