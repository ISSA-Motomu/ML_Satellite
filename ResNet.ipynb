{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264dbbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tensorflow\n",
    "from tensorflow.keras.layers import Input, Conv2D, Activation, Add\n",
    "\n",
    "def residual_block(input_tensor, num_filters,strides=1):\n",
    "    \"\"\"\n",
    "    入力と出力のサイズが変わらない、基本的な残差ブロック\n",
    "    残差：Residual\n",
    "    Output = f(Input)+Input\n",
    "        ここでFは2回の畳み込みとReLU活性化\n",
    "\n",
    "    Skip Connection\n",
    "        残差分だけを学習することで、層が深くなっても勾配損失問題を防ぐ\n",
    "    \n",
    "    Conv\n",
    "        畳み込みをすると通常は画面の端っこが削れて小さくなるが、padding='same'を指定して周りに余白をつける\n",
    "        そうすると入力と出力のサイズが変わらなくなる\n",
    "\n",
    "    Add()([x,shortcut])\n",
    "        KerasのFunctional APIの書き方\n",
    "            ➀足し算マシーン(Addレイヤー)の生成、ここでAddは単純に足し算をするだけなので()の中に複雑な設定が必要ない\n",
    "            ➁足し算マシーンに[x,shortcut]というリストの形状にして足し算を実行する\n",
    "\n",
    "    Strides\n",
    "        畳み込みの移動幅を指定するパラメータ\n",
    "        1なら通常通り1pxずつ、2なら2pxずつ移動する(1個飛ばし)ので、出力サイズが半分になる\n",
    "\n",
    "    num_filters\n",
    "        各num_filterは畳み込み層で検知した特徴マップを持っている\n",
    "        例えば浅い層のフィルターではエッジ検出、深い層ではより複雑なパターンを検出する\n",
    "            エッジ：隣り合う画素(ピクセル)が急激に変化している部分\n",
    "    \"\"\"\n",
    "    shortcut = input_tensor\n",
    "\n",
    "    # 畳み込み一回目\n",
    "    x = Conv2D(num_filters, (3, 3), padding='same',strides=strides)(input_tensor)\n",
    "    x=BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "\n",
    "    x = Conv2D(num_filters, (3, 3), padding='same')(x) #畳み込み二回目\n",
    "\n",
    "\n",
    "    if strides > 1 or input_tensor.shape[-1] != num_filters:\n",
    "        \"\"\"\n",
    "        サイズが変わる、またはチャンネル数が変わるとき\n",
    "        .shape[-1]は最後の要素、つまりchannnel\n",
    "        \"\"\"\n",
    "        shortcut = Conv2D(num_filters, (1, 1), padding='same',strides=strides)(shortcut)\n",
    "\n",
    "    x = Add()([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a9253b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense\n",
    "\n",
    "def build_simple_resnet(input_shape=(128, 128, 3), num_classes=10):\n",
    "    \"\"\"\n",
    "    ResNetの簡易モデルの作成\n",
    "        画像分類タスクでは、画像の特徴の身を知りたいので畳み込み層のエンコードしか必要ない\n",
    "        セグメンテーションは位置情報も必要なのでdecodeも必要になる\n",
    "        ResNet18の18は層の数、50や152などがある\n",
    "\n",
    "    Projection(射影)\n",
    "            ➀入力の特徴マップのサイズを変換する\n",
    "            ➁フィルター数(channel数)を変更する\n",
    "\n",
    "    GlobalAveragePooling2D\n",
    "        Strides=1は画像サイズを変えないまま特徴をしっかり抽出する\n",
    "        \n",
    "    \"\"\"\n",
    "    inputs = Input(input_shape)\n",
    "    x = residual_block(inputs, num_filters=64, strides=1)\n",
    "\n",
    "    x = residual_block(x, num_filters=64, strides=1)   #サイズを変えないまま特徴をしっかり見極める\n",
    "    x = residual_block(x, num_filters=64, strides=1) \n",
    "    \n",
    "    x = residual_block(x, num_filters=128, strides=2)   #サイズを半分にする(Projection Block)\n",
    "    x = residual_block(x, num_filters=128, strides=1) \n",
    "    \n",
    "    # --- 出口 (Output Layers) ---\n",
    "    # Q4: 画像全体を平均して1次元のベクトルにする\n",
    "    x = GlobalAveragePooling2D()(x) \n",
    "    \n",
    "    # 最終判定 (10クラス分類なので softmax)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    return Model(inputs, outputs)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
